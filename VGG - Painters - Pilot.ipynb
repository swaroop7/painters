{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/swaroop/Downloads/deeplearning_nbs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify we are in the lesson1 directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = '/home/swaroop/Downloads/deeplearning_nbs'\n",
    "DATA_HOME_DIR = '/home/swaroop/Downloads/deeplearning_nbs'+'/data/pilot-dogscats-inside'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Allow relative imports to directories above lesson1/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories \n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/swaroop/Downloads/deeplearning_nbs/data/pilot-dogscats-inside\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR  #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "\n",
    "img_width, img_height = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size=4\n",
    "no_of_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 2 classes.\n",
      "Found 4 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "#Not sure if we set this for all fits\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Running batch_size: 4\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: [[[[ 160.  171.  172. ...,  135.  143.  124.]\n   [ 155.  146.  157. ...,  135.  168.  138.]\n   [ 147.  149.  145. ...,  124.  158.  181.]\n   ..., \n   [   1.    0.   12. ...,  178.  219.  163.]\n   [   8.   33.   18. ...,   56.   84.   68.]\n   [  19.    4.    5. ...,  130.  131.   77.]]\n\n  [[ 189.  208.  201. ...,  132.  142.  124.]\n   [ 184.  177.  185. ...,  137.  170.  141.]\n   [ 176.  175.  175. ...,  130.  164.  188.]\n   ..., \n   [   2.    1.   20. ...,  181.  216.  157.]\n   [  10.   40.   28. ...,   35.   84.   54.]\n   [  19.    9.   11. ...,  133.  135.   77.]]\n\n  [[ 233.  250.  243. ...,  149.  150.  124.]\n   [ 228.  223.  232. ...,  152.  182.  146.]\n   [ 220.  224.  227. ...,  146.  176.  198.]\n   ..., \n   [   7.    0.    7. ...,  102.  163.  133.]\n   [   5.   22.    4. ...,   40.    0.   25.]\n   [  27.    3.    9. ...,   78.  121.   39.]]]\n\n\n [[[ 162.  171.  155. ...,  142.  136.  137.]\n   [ 159.  157.  152. ...,  128.  133.  139.]\n   [ 164.  166.  158. ...,  130.  128.  133.]\n   ..., \n   [  33.   26.   18. ...,   11.   14.   18.]\n   [  18.   38.   21. ...,   14.   11.   14.]\n   [  23.   22.   23. ...,   15.   15.   17.]]\n\n  [[ 144.  160.  149. ...,  139.  128.  127.]\n   [ 149.  145.  148. ...,  131.  131.  137.]\n   [ 153.  155.  156. ...,  134.  130.  132.]\n   ..., \n   [  28.   27.   23. ...,   14.   17.   19.]\n   [  21.   36.   25. ...,   14.   16.   19.]\n   [  28.   27.   28. ...,   18.   20.   22.]]\n\n  [[ 142.  164.  161. ...,  150.  141.  135.]\n   [ 157.  155.  165. ...,  150.  142.  148.]\n   [ 161.  163.  178. ...,  159.  151.  150.]\n   ..., \n   [  32.   29.   29. ...,   19.   22.   24.]\n   [  26.   37.   26. ...,   22.   19.   22.]\n   [  32.   31.   32. ...,   27.   24.   26.]]]\n\n\n [[[ 113.   91.  132. ...,  180.  111.  170.]\n   [ 135.  138.  143. ...,  155.  136.  135.]\n   [ 140.  126.  136. ...,  134.  157.  132.]\n   ..., \n   [ 157.  101.   97. ...,   65.   62.  112.]\n   [ 121.  116.  105. ...,  133.  131.  113.]\n   [ 150.  131.  138. ...,   46.   41.   47.]]\n\n  [[ 130.  110.  158. ...,  212.  143.  204.]\n   [ 161.  161.  166. ...,  194.  168.  164.]\n   [ 170.  154.  160. ...,  178.  190.  164.]\n   ..., \n   [ 182.  120.  116. ...,   75.   74.  124.]\n   [ 147.  141.  131. ...,  152.  157.  131.]\n   [ 176.  157.  163. ...,   71.   70.   72.]]\n\n  [[ 120.  124.  193. ...,  235.  166.  216.]\n   [ 188.  202.  218. ...,  251.  227.  208.]\n   [ 206.  193.  204. ...,  241.  255.  211.]\n   ..., \n   [ 178.  126.  133. ...,   74.   72.  122.]\n   [ 144.  145.  146. ...,  146.  148.  131.]\n   [ 173.  156.  167. ...,   68.   66.   76.]]]\n\n\n ..., \n [[[ 226.  239.  231. ...,  245.  254.  255.]\n   [ 224.  228.  219. ...,  246.  252.  254.]\n   [ 220.  218.  215. ...,  247.  249.  250.]\n   ..., \n   [ 101.  129.   97. ...,  137.  152.  110.]\n   [  87.  143.  116. ...,  126.  164.  153.]\n   [  99.  151.  170. ...,  133.  127.  128.]]\n\n  [[ 220.  234.  226. ...,  247.  253.  252.]\n   [ 224.  229.  220. ...,  248.  253.  251.]\n   [ 226.  224.  222. ...,  253.  251.  250.]\n   ..., \n   [ 125.  152.  132. ...,  154.  174.  117.]\n   [ 103.  162.  156. ...,  158.  196.  178.]\n   [ 112.  154.  179. ...,  154.  141.  148.]]\n\n  [[ 204.  214.  204. ...,  223.  225.  223.]\n   [ 212.  213.  202. ...,  234.  235.  232.]\n   [ 216.  210.  206. ...,  243.  240.  238.]\n   ..., \n   [  49.   48.   50. ...,   86.  110.   84.]\n   [  32.   54.   59. ...,  111.  113.   94.]\n   [  68.   65.   98. ...,  121.   80.   85.]]]\n\n\n [[[  82.   52.   65. ...,  149.  131.  104.]\n   [ 110.  102.   18. ...,   66.  111.   88.]\n   [  93.   41.    8. ...,   82.  140.   84.]\n   ..., \n   [  35.   46.   36. ...,  141.  127.  217.]\n   [  14.   47.    6. ...,  104.  146.  236.]\n   [  38.   27.   25. ...,  143.  130.  143.]]\n\n  [[  40.   47.   34. ...,  128.  112.   80.]\n   [  59.   42.    8. ...,   46.   84.   75.]\n   [  42.   16.    0. ...,   57.  116.   48.]\n   ..., \n   [  28.   29.   30. ...,  167.  143.  212.]\n   [   4.   41.    0. ...,  128.  168.  231.]\n   [  30.   21.   15. ...,  158.  154.  167.]]\n\n  [[  42.   44.   39. ...,  107.   97.   56.]\n   [  68.   52.   16. ...,   35.   73.   66.]\n   [  49.   19.    3. ...,   52.  114.   34.]\n   ..., \n   [  46.   35.   34. ...,  156.  116.  192.]\n   [  29.   55.    4. ...,  114.  156.  209.]\n   [  54.   35.   23. ...,  137.  140.  141.]]]\n\n\n [[[ 119.  120.   90. ...,  104.  140.  103.]\n   [ 122.   99.   95. ...,  111.  169.  109.]\n   [ 108.  105.   93. ...,  118.  139.  103.]\n   ..., \n   [ 157.  131.   90. ...,   96.   97.   94.]\n   [ 144.  167.  151. ...,   87.  104.   86.]\n   [ 128.  149.  187. ...,   82.  102.   68.]]\n\n  [[ 134.  132.  112. ...,  111.  149.  115.]\n   [ 135.  117.  108. ...,  118.  176.  118.]\n   [ 126.  120.  109. ...,  126.  147.  113.]\n   ..., \n   [ 157.  135.   92. ...,  108.  112.  106.]\n   [ 144.  171.  153. ...,  106.  111.   93.]\n   [ 132.  159.  185. ...,   96.  106.   75.]]\n\n  [[ 165.  180.  135. ...,  130.  156.  111.]\n   [ 180.  165.  143. ...,  136.  192.  151.]\n   [ 162.  175.  142. ...,  139.  168.  138.]\n   ..., \n   [ 157.  136.  104. ...,  104.  105.   96.]\n   [ 142.  174.  166. ...,  104.   95.   75.]\n   [ 131.  151.  173. ...,   96.   91.   44.]]]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-df2c7b21141a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Running epoch: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Running batch_size: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlatest_weights_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ft%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#vgg.model.save_weights(results_path+latest_weights_filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/deeplearning_nbs/vgg16.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batches, val_batches, nb_epoch)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         self.model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n\u001b[0;32m--> 117\u001b[0;31m                 validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1540\u001b[0m                                          \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                                          \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1543\u001b[0m                     \u001b[0;31m# build batch logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                     \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: [[[[ 160.  171.  172. ...,  135.  143.  124.]\n   [ 155.  146.  157. ...,  135.  168.  138.]\n   [ 147.  149.  145. ...,  124.  158.  181.]\n   ..., \n   [   1.    0.   12. ...,  178.  219.  163.]\n   [   8.   33.   18. ...,   56.   84.   68.]\n   [  19.    4.    5. ...,  130.  131.   77.]]\n\n  [[ 189.  208.  201. ...,  132.  142.  124.]\n   [ 184.  177.  185. ...,  137.  170.  141.]\n   [ 176.  175.  175. ...,  130.  164.  188.]\n   ..., \n   [   2.    1.   20. ...,  181.  216.  157.]\n   [  10.   40.   28. ...,   35.   84.   54.]\n   [  19.    9.   11. ...,  133.  135.   77.]]\n\n  [[ 233.  250.  243. ...,  149.  150.  124.]\n   [ 228.  223.  232. ...,  152.  182.  146.]\n   [ 220.  224.  227. ...,  146.  176.  198.]\n   ..., \n   [   7.    0.    7. ...,  102.  163.  133.]\n   [   5.   22.    4. ...,   40.    0.   25.]\n   [  27.    3.    9. ...,   78.  121.   39.]]]\n\n\n [[[ 162.  171.  155. ...,  142.  136.  137.]\n   [ 159.  157.  152. ...,  128.  133.  139.]\n   [ 164.  166.  158. ...,  130.  128.  133.]\n   ..., \n   [  33.   26.   18. ...,   11.   14.   18.]\n   [  18.   38.   21. ...,   14.   11.   14.]\n   [  23.   22.   23. ...,   15.   15.   17.]]\n\n  [[ 144.  160.  149. ...,  139.  128.  127.]\n   [ 149.  145.  148. ...,  131.  131.  137.]\n   [ 153.  155.  156. ...,  134.  130.  132.]\n   ..., \n   [  28.   27.   23. ...,   14.   17.   19.]\n   [  21.   36.   25. ...,   14.   16.   19.]\n   [  28.   27.   28. ...,   18.   20.   22.]]\n\n  [[ 142.  164.  161. ...,  150.  141.  135.]\n   [ 157.  155.  165. ...,  150.  142.  148.]\n   [ 161.  163.  178. ...,  159.  151.  150.]\n   ..., \n   [  32.   29.   29. ...,   19.   22.   24.]\n   [  26.   37.   26. ...,   22.   19.   22.]\n   [  32.   31.   32. ...,   27.   24.   26.]]]\n\n\n [[[ 113.   91.  132. ...,  180.  111.  170.]\n   [ 135.  138.  143. ...,  155.  136.  135.]\n   [ 140.  126.  136. ...,  134.  157.  132.]\n   ..., \n   [ 157.  101.   97. ...,   65.   62.  112.]\n   [ 121.  116.  105. ...,  133.  131.  113.]\n   [ 150.  131.  138. ...,   46.   41.   47.]]\n\n  [[ 130.  110.  158. ...,  212.  143.  204.]\n   [ 161.  161.  166. ...,  194.  168.  164.]\n   [ 170.  154.  160. ...,  178.  190.  164.]\n   ..., \n   [ 182.  120.  116. ...,   75.   74.  124.]\n   [ 147.  141.  131. ...,  152.  157.  131.]\n   [ 176.  157.  163. ...,   71.   70.   72.]]\n\n  [[ 120.  124.  193. ...,  235.  166.  216.]\n   [ 188.  202.  218. ...,  251.  227.  208.]\n   [ 206.  193.  204. ...,  241.  255.  211.]\n   ..., \n   [ 178.  126.  133. ...,   74.   72.  122.]\n   [ 144.  145.  146. ...,  146.  148.  131.]\n   [ 173.  156.  167. ...,   68.   66.   76.]]]\n\n\n ..., \n [[[ 226.  239.  231. ...,  245.  254.  255.]\n   [ 224.  228.  219. ...,  246.  252.  254.]\n   [ 220.  218.  215. ...,  247.  249.  250.]\n   ..., \n   [ 101.  129.   97. ...,  137.  152.  110.]\n   [  87.  143.  116. ...,  126.  164.  153.]\n   [  99.  151.  170. ...,  133.  127.  128.]]\n\n  [[ 220.  234.  226. ...,  247.  253.  252.]\n   [ 224.  229.  220. ...,  248.  253.  251.]\n   [ 226.  224.  222. ...,  253.  251.  250.]\n   ..., \n   [ 125.  152.  132. ...,  154.  174.  117.]\n   [ 103.  162.  156. ...,  158.  196.  178.]\n   [ 112.  154.  179. ...,  154.  141.  148.]]\n\n  [[ 204.  214.  204. ...,  223.  225.  223.]\n   [ 212.  213.  202. ...,  234.  235.  232.]\n   [ 216.  210.  206. ...,  243.  240.  238.]\n   ..., \n   [  49.   48.   50. ...,   86.  110.   84.]\n   [  32.   54.   59. ...,  111.  113.   94.]\n   [  68.   65.   98. ...,  121.   80.   85.]]]\n\n\n [[[  82.   52.   65. ...,  149.  131.  104.]\n   [ 110.  102.   18. ...,   66.  111.   88.]\n   [  93.   41.    8. ...,   82.  140.   84.]\n   ..., \n   [  35.   46.   36. ...,  141.  127.  217.]\n   [  14.   47.    6. ...,  104.  146.  236.]\n   [  38.   27.   25. ...,  143.  130.  143.]]\n\n  [[  40.   47.   34. ...,  128.  112.   80.]\n   [  59.   42.    8. ...,   46.   84.   75.]\n   [  42.   16.    0. ...,   57.  116.   48.]\n   ..., \n   [  28.   29.   30. ...,  167.  143.  212.]\n   [   4.   41.    0. ...,  128.  168.  231.]\n   [  30.   21.   15. ...,  158.  154.  167.]]\n\n  [[  42.   44.   39. ...,  107.   97.   56.]\n   [  68.   52.   16. ...,   35.   73.   66.]\n   [  49.   19.    3. ...,   52.  114.   34.]\n   ..., \n   [  46.   35.   34. ...,  156.  116.  192.]\n   [  29.   55.    4. ...,  114.  156.  209.]\n   [  54.   35.   23. ...,  137.  140.  141.]]]\n\n\n [[[ 119.  120.   90. ...,  104.  140.  103.]\n   [ 122.   99.   95. ...,  111.  169.  109.]\n   [ 108.  105.   93. ...,  118.  139.  103.]\n   ..., \n   [ 157.  131.   90. ...,   96.   97.   94.]\n   [ 144.  167.  151. ...,   87.  104.   86.]\n   [ 128.  149.  187. ...,   82.  102.   68.]]\n\n  [[ 134.  132.  112. ...,  111.  149.  115.]\n   [ 135.  117.  108. ...,  118.  176.  118.]\n   [ 126.  120.  109. ...,  126.  147.  113.]\n   ..., \n   [ 157.  135.   92. ...,  108.  112.  106.]\n   [ 144.  171.  153. ...,  106.  111.   93.]\n   [ 132.  159.  185. ...,   96.  106.   75.]]\n\n  [[ 165.  180.  135. ...,  130.  156.  111.]\n   [ 180.  165.  143. ...,  136.  192.  151.]\n   [ 162.  175.  142. ...,  139.  168.  138.]\n   ..., \n   [ 157.  136.  104. ...,  104.  105.   96.]\n   [ 142.  174.  166. ...,  104.   95.   75.]\n   [ 131.  151.  173. ...,   96.   91.   44.]]]]"
     ]
    }
   ],
   "source": [
    "# swaroop code based on lecture \n",
    "\n",
    "#vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "\n",
    "latest_weights_filename = None\n",
    "no_of_epochs=2\n",
    "\n",
    "for batch_size in [4]:\n",
    "    for epoch in range(no_of_epochs):\n",
    "        print (\"Running epoch: %d\" % epoch)\n",
    "        print (\"Running batch_size: %d\" % batch_size)\n",
    "        vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "        latest_weights_filename = 'ft%d.h5' % epoch\n",
    "        #vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "    print (\"Completed %s fit operations\" % no_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 1]\n",
      "[  8.1395e-01   9.9993e-01   7.5594e-01   9.9969e-01   1.3625e-03   5.9084e-03   9.8574e-01\n",
      "   1.9832e-13]\n",
      "[ 0.  0.  0.  0.  1.  1.  0.  1.]\n",
      "ROC -  0.875\n"
     ]
    }
   ],
   "source": [
    "filenames = batches.filenames\n",
    "expected_labels = batches.classes #0 or 1\n",
    "\n",
    "print (expected_labels)\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = preds[:,0]\n",
    "#print (our_predictions)\n",
    "our_labels = np.round(1-our_predictions)\n",
    "print (our_predictions)\n",
    "print (our_labels)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "\n",
    "\n",
    "print ('ROC - ',roc_auc_score(expected_labels, preds[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0]\n",
      " [1 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f291c56e828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras' *fit()* function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"*epoch*\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting. \n",
    "\n",
    "- **Tip**: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Log Loss](http://wiki.fast.ai/index.php/Log_Loss) doesn't support probability values of 0 or 1--they are undefined (and we have many). Fortunately, Kaggle helps us by offsetting our 0s and 1s by a very small value. So if we upload our submission now we will have lots of .99999999 and .000000001 values. This seems good, right?\n",
    "\n",
    "Not so. There is an additional twist due to how log loss is calculated--log loss rewards predictions that are confident and correct (p=.9999,label=1), but it punishes predictions that are confident and wrong far more (p=.0001,label=1). See visualization below."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
