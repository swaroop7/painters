{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "make_submission() generates predictions for the Kaggle Painter by Numbers competion\n",
    "using simple features (image size, aspect ratio and bits/pixel^2)\n",
    "author: Swaroop Krothapalli - extended code of small yello duck\n",
    "https://github.com/swaroop7/painters\n",
    "'''\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "np.set_printoptions(precision=3, linewidth=100)\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225592\n",
      "277853\n",
      "305944\n",
      "316282\n",
      "328975\n",
      "338205\n",
      "340697\n",
      "347002\n",
      "350221\n",
      "351559\n",
      "353990\n",
      "356619\n",
      "360412\n",
      "362681\n",
      "364978\n",
      "366299\n",
      "367267\n",
      "368014\n",
      "368932\n",
      "369979\n",
      "371002\n",
      "371539\n",
      "372291\n",
      "373494\n",
      "373991\n",
      "374182\n",
      "374494\n",
      "374643\n",
      "375849\n",
      "376040\n",
      "377505\n",
      "378020\n",
      "378448\n",
      "378532\n",
      "378784\n",
      "379422\n",
      "379635\n",
      "380000\n",
      "380042\n",
      "380413\n",
      "380663\n",
      "380761\n",
      "380977\n",
      "381096\n",
      "381347\n",
      "381806\n",
      "381937\n",
      "383193\n",
      "part 1 done\n"
     ]
    }
   ],
   "source": [
    "input_file = open('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\train_conv4_1.txt')\n",
    "output_file = open('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\train_processed_conv4_1.txt','w')\n",
    "\n",
    "random = {}\n",
    "\n",
    "output = set()\n",
    "\n",
    "\n",
    "for line in input_file:\n",
    "    line = line[2:]\n",
    "    for each_word in line.split():\n",
    "        words = each_word.split(\":\")\n",
    "        output.add(words[0].strip())\n",
    "    print len(output)\n",
    "\n",
    "print 'part 1 done'\n",
    "\n",
    "for x in output:\n",
    "    random[x] = 0.\n",
    "\n",
    "\n",
    "input_file.close()\n",
    "input_file = open('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\train_conv4_1.txt')\n",
    "\n",
    "for line in input_file:\n",
    "    line = line[2:]\n",
    "    for each_word in line.split():\n",
    "        words = each_word.strip().split(\":\")\n",
    "        random[words[0]] = round(float(words[1]), 4)\n",
    "            \n",
    "    for key,value in random.items():\n",
    "        output_file.write(str(value)+' ')\n",
    "        random[key] = 0.\n",
    "    output_file.write('\\n')\n",
    "    \n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n",
      "line done\n"
     ]
    }
   ],
   "source": [
    "input_file = open('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\test_conv4_1.txt')\n",
    "output_file = open('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\test_processed_conv4_1.txt','w')\n",
    "\n",
    "for line in input_file:\n",
    "    line = line[2:]\n",
    "    for each_word in line.split():\n",
    "        words = each_word.strip().split(\":\")\n",
    "        if words[0] in output:\n",
    "            random[words[0]] = round(float(words[1]), 4)\n",
    "            \n",
    "    for key,value in random.items():\n",
    "        output_file.write(str(value)+' ')\n",
    "        random[key] = 0.\n",
    "    print 'line done'\n",
    "    output_file.write('\\n')\n",
    "    \n",
    "input_file.close()\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48L, 383193L)\n",
      "(48L, 383193L)\n",
      "(10L, 383193L)\n",
      "(48L,)\n",
      "(10L,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\train_processed_conv4_1.txt')\n",
    "y_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\y_train_conv5_1.txt')\n",
    "x_test = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\test_processed_conv4_1.txt')\n",
    "y_test = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\y_test_conv5_1.txt')\n",
    "\n",
    "print x_train.shape\n",
    "\n",
    "'''\n",
    "rand_numbers = []\n",
    "\n",
    "for x in range(1,500):\n",
    "    rand_numbers.append(random.randint(1,79928))\n",
    "    \n",
    "new_x_train = x_train[:, rand_numbers]\n",
    "\n",
    "new_x_test = x_test[:, rand_numbers]\n",
    "'''\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_results(clf, y_test, y_pred, y_pred_prob):\n",
    "    #y_pred_prob = clf.predict_proba(y_test)[:,1]\n",
    "    #y_pred = clf.predict(y_test)\n",
    "    print 'ROC - ',roc_auc_score(y_test, y_pred_prob)\n",
    "    print 'Accuracy - ',accuracy_score(y_test, y_pred)\n",
    "    print 'Confusion Matrix - ', confusion_matrix(y_test, y_pred)\n",
    "    #print 'Precision - ',precision_score(y_test, y_pred ),'Recall - ',recall_score(y_test, y_pred),'F1- Score',f1_score(y_test, y_pred),'\\n'\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print classification_report(y_test, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48L, 383193L) (48L,)\n",
      "[[ 0.  6.]\n",
      " [ 1.  4.]]\n",
      "[ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape, y_train.shape\n",
    "#training, testing, y_training, y_testing = train_test_split(new_x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "actual_training, validation, y_actual_training, y_validation = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "#print training.shape, testing.shape\n",
    "#print y_training, y_testing\n",
    "#print itemfreq(y_training)\n",
    "#print itemfreq(y_testing)\n",
    "print itemfreq(y_validation)\n",
    "#print itemfreq(y_train)\n",
    "\n",
    "print y_validation\n",
    "# print y_actual_training\n",
    "# print actual_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 0.771825396825 0.122708268768 1.0 0.7\n",
      "ROC -  0.5625\n",
      "Accuracy -  0.7\n",
      "Confusion Matrix -  [[5 1]\n",
      " [2 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.71      0.83      0.77         6\n",
      "    class 1       0.67      0.50      0.57         4\n",
      "\n",
      "avg / total       0.70      0.70      0.69        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "for i in xrange(1):\n",
    "    clf = RandomForestClassifier(n_estimators=95, class_weight='balanced',  random_state = 42)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, scores.mean(), scores.std(), accuracy_score(y_validation, y_pred_valid), accuracy_score(y_test, clf.predict(x_test))\n",
    "    \n",
    "print_results(clf, y_test, clf.predict(x_test), clf.predict_proba(x_test)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 \t0.711904761905 \t0.158722222024 \t0.6 \t0.6\n",
      "ROC -  0.520833333333\n",
      "Accuracy -  0.6\n",
      "Confusion Matrix -  [[5 1]\n",
      " [3 1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.62      0.83      0.71         6\n",
      "    class 1       0.50      0.25      0.33         4\n",
      "\n",
      "avg / total       0.57      0.60      0.56        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGB\n",
    "    \n",
    "learning_r_col = [0.0001, 0.001, 0.01, 0.02, 0.03, 0.04,0.05,0.06,0.07,0.08,0.09,0.1]    \n",
    "    \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "    \n",
    "for i in xrange(1):\n",
    "    clf = xgb.XGBClassifier(max_depth=3, n_estimators=5, learning_rate=0.001) #objective='multi:softprob'\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_test, clf.predict(x_test))\n",
    "\n",
    "print_results(clf, y_test, clf.predict(x_test), clf.predict_proba(x_test)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 0.661111111111 0.0809212514065 0.8 0.5\n",
      "ROC -  0.416666666667\n",
      "Accuracy -  0.5\n",
      "Confusion Matrix -  [[4 2]\n",
      " [3 1]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.57      0.67      0.62         6\n",
      "    class 1       0.33      0.25      0.29         4\n",
      "\n",
      "avg / total       0.48      0.50      0.48        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic\n",
    "    \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"    \n",
    "    \n",
    "for i in xrange(1):  # , max_iter = i\n",
    "    clf = linear_model.LogisticRegression( class_weight='balanced', penalty = 'l1')\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, scores.mean(), scores.std(), accuracy_score(y_validation, y_pred_valid), accuracy_score(y_test, clf.predict(x_test))\n",
    "    \n",
    "print_results(clf, y_test, clf.predict(x_test), clf.predict_proba(x_test)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS of 5 fold CV\n",
      "Mean Accuracy  \tSTD \tValidation  \tTest\n",
      "0 \t0.838492063492 \t0.0632385813075 \t0.9 \t0.5\n",
      "Confusion Matrix -  [[3 3]\n",
      " [2 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.60      0.50      0.55         6\n",
      "    class 1       0.40      0.50      0.44         4\n",
      "\n",
      "avg / total       0.52      0.50      0.51        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "    \n",
    "print \"ACCURACY RESUTLS of 5 fold CV\"    \n",
    "print \"Mean Accuracy \",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"    \n",
    "\n",
    "iter = [5,10,100,500,1000]\n",
    "\n",
    "for i in xrange(1):\n",
    "    clf = LinearSVC(class_weight = 'balanced', dual = False)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5 )\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_test, clf.predict(x_test))\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "print 'Confusion Matrix - ', confusion_matrix(y_test, clf.predict(x_test))\n",
    "print classification_report(y_test, clf.predict(x_test), target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualize the 4_1 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:21: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "import time\n",
    "#from IPython.display import Image\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\4_1')\n",
    "\n",
    "list_im = []\n",
    "\n",
    "for i in xrange(1,500):\n",
    "    k = i*29\n",
    "    arr = np.genfromtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\das2_conv4_1.txt', skip_header=k, max_rows = 28)\n",
    "    \n",
    "    arr = arr/np.amax(arr)\n",
    "\n",
    "    im = Image.fromarray(np.uint8(cm.gist_heat(arr)*255))\n",
    "    \n",
    "    #imshow(im)\n",
    "    im.save('output'+str(i)+'.jpg')\n",
    "    list_im.append('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\cnn_features\\\\april27\\\\4_1\\\\output'+str(i)+'.jpg') \n",
    "    \n",
    "\n",
    "\n",
    "imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "# save that beautiful picture\n",
    "imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "imgs_comb.save( 'Trifecta.jpg' )    \n",
    "\n",
    "# for a vertical stacking it is simple: use vstack\n",
    "imgs_comb = np.vstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "imgs_comb.save( 'Trifecta_vertical.jpg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
