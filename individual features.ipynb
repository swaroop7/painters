{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "make_submission() generates predictions for the Kaggle Painter by Numbers competion\n",
    "using simple features (image size, aspect ratio and bits/pixel^2)\n",
    "author: Swaroop Krothapalli - extended code of small yello duck\n",
    "https://github.com/swaroop7/painters\n",
    "'''\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(precision=3, linewidth=100)\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31L,) (31L,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\x_train_pilot.txt')\n",
    "y_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\y_train_pilot.txt')\n",
    "\n",
    "#x_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\x_train_wyeth.txt')\n",
    "#y_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\y_train_wyeth.txt')\n",
    "\n",
    "\n",
    "x_train = x_train[:,7]  # Index has to be varied for each feature. \n",
    "y_train = y_train\n",
    "\n",
    "print x_train.shape, y_train.shape\n",
    "training, testing, y_training, y_testing = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "actual_training, validation, y_actual_training, y_validation = train_test_split(training, y_training, test_size=0.2, stratify=y_training, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(clf, y_test, y_pred, y_pred_prob):\n",
    "    #y_pred_prob = clf.predict_proba(y_test)[:,1]\n",
    "    #y_pred = clf.predict(y_test)\n",
    "    print 'ROC - ',roc_auc_score(y_test, y_pred_prob)\n",
    "    #print 'Confusion Matrix - ', confusion_matrix(y_test, y_pred)\n",
    "    #print 'Precision - ',precision_score(y_test, y_pred ),'Recall - ',recall_score(y_test, y_pred),'F1- Score',f1_score(y_test, y_pred),'\\n'\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print classification_report(y_test, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19L,)\n",
      "(19L,)\n",
      "(5L,)\n",
      "(5L,)\n",
      "starting fit\n",
      "SVM - Sigmoid Scores\n",
      "Accuracy: 0.47 (+/- 0.13)\n",
      "validation_score 0.4\n",
      "ROC -  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00         4\n",
      "    class 1       0.43      1.00      0.60         3\n",
      "\n",
      "avg / total       0.18      0.43      0.26         7\n",
      "\n",
      "SVM - RBF Kernel\n",
      "validation_score 0.4\n",
      "ROC -  0.333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.50      0.25      0.33         4\n",
      "    class 1       0.40      0.67      0.50         3\n",
      "\n",
      "avg / total       0.46      0.43      0.40         7\n",
      "\n",
      "Accuracy: 0.47 (+/- 0.13)\n",
      "Random Forest\n",
      "validation_score 0.6\n",
      "ROC -  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00         4\n",
      "    class 1       0.33      0.67      0.44         3\n",
      "\n",
      "avg / total       0.14      0.29      0.19         7\n",
      "\n",
      "Accuracy: 0.67 (+/- 0.46)\n",
      "Gaussian NB\n",
      "validation_score 0.2\n",
      "ROC -  0.583333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.50      0.50      0.50         4\n",
      "    class 1       0.33      0.33      0.33         3\n",
      "\n",
      "avg / total       0.43      0.43      0.43         7\n",
      "\n",
      "Accuracy: 0.42 (+/- 0.41)\n",
      "Bernoulli NB\n",
      "validation_score 0.6\n",
      "ROC -  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.57      1.00      0.73         4\n",
      "    class 1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.33      0.57      0.42         7\n",
      "\n",
      "Accuracy: 0.53 (+/- 0.13)\n",
      "SVM - Linear Kernel\n",
      "validation_score 0.2\n",
      "Accuracy: 0.25 (+/- 0.45)\n",
      "KNN\n",
      "validation_score 0.8\n",
      "ROC -  0.375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.33      0.25      0.29         4\n",
      "    class 1       0.25      0.33      0.29         3\n",
      "\n",
      "avg / total       0.30      0.29      0.29         7\n",
      "\n",
      "Accuracy: 0.45 (+/- 0.73)\n",
      "Logistic\n",
      "validation_score 0.2\n",
      "ROC -  0.416666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.60      0.75      0.67         4\n",
      "    class 1       0.50      0.33      0.40         3\n",
      "\n",
      "avg / total       0.56      0.57      0.55         7\n",
      "\n",
      "Accuracy: 0.40 (+/- 0.51)\n",
      "XGBoost\n",
      "validation_score 0.2\n",
      "ROC -  0.625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.67      0.50      0.57         4\n",
      "    class 1       0.50      0.67      0.57         3\n",
      "\n",
      "avg / total       0.60      0.57      0.57         7\n",
      "\n",
      "Accuracy: 0.50 (+/- 0.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaroop\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def train_classifier(x_train, y_train, x_cv, y_cv):    \n",
    "    clf1 = SVC(kernel = 'sigmoid', probability=True, class_weight='balanced')\n",
    "    clf2 = SVC(kernel = 'rbf', probability=True, class_weight='balanced')\n",
    "    clf3 = RandomForestClassifier(n_estimators=5, class_weight='balanced')\n",
    "    clf4 = GaussianNB()\n",
    "    clf5 = BernoulliNB() \n",
    "    clf6 = LinearSVC(class_weight = 'balanced', dual = False)\n",
    "    clf7 = SVC(kernel = 'poly', probability=True, class_weight='balanced', degree=2, C=1.0, tol = 0.1)\n",
    "    clf8 = neighbors.KNeighborsClassifier()\n",
    "    clf9 = linear_model.LogisticRegression( class_weight='balanced')\n",
    "    clf10 = xgb.XGBClassifier(max_depth=2, n_estimators=10, learning_rate=0.05) #objective='multi:softprob'\n",
    "    print 'starting fit'\n",
    "    #print x_train\n",
    "\n",
    "    print \"SVM - Sigmoid Scores\"\n",
    "    clf1.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf1, x_train[:, None], y_train, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf1.predict(x_cv[:, None]))\n",
    "    print_results(clf1, y_testing, clf1.predict(testing[:, None]), clf1.predict_proba(testing[:, None])[:,1] )    \n",
    "\n",
    "    print \"SVM - RBF Kernel\"\n",
    "    clf2.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf1, x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf2.predict(x_cv[:, None]))\n",
    "    print_results(clf2, y_testing, clf2.predict(testing[:, None]), clf2.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Random Forest\"\n",
    "    clf3.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf3,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf3.predict(x_cv[:, None]))\n",
    "    print_results(clf3, y_testing, clf3.predict(testing[:, None]), clf3.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Gaussian NB\"\n",
    "    clf4.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf4, x_train[:, None], y_train, cv=3)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf4.predict(x_cv[:, None]))\n",
    "    print_results(clf4, y_testing, clf4.predict(testing[:, None]), clf4.predict_proba(testing[:, None])[:,1] )        \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Bernoulli NB\"\n",
    "    clf5.fit(x_train.reshape((19,1)), y_train) \n",
    "    scores = cross_validation.cross_val_score(clf5,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf5.predict(x_cv[:, None]))\n",
    "    print_results(clf5, y_testing, clf5.predict(testing[:, None]), clf5.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"SVM - Linear Kernel\"\n",
    "    clf6.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf6, x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf6.predict(x_cv[:, None]))\n",
    "    #print_results(clf6, y_testing, clf6.predict(testing[:, None]), clf6.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    #clf7.fit(x_train.reshape((19,1)), y_train) \n",
    "    print \"KNN\"\n",
    "    clf8.fit(x_train.reshape((19,1)), y_train) \n",
    "    scores = cross_validation.cross_val_score(clf8,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf8.predict(x_cv[:, None]))\n",
    "    print_results(clf8, y_testing, clf8.predict(testing[:, None]), clf8.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Logistic\"\n",
    "    clf9.fit(x_train.reshape((19,1)), y_train) \n",
    "    scores = cross_validation.cross_val_score(clf9,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf9.predict(x_cv[:, None]))\n",
    "    print_results(clf9, y_testing, clf9.predict(testing[:, None]), clf9.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"XGBoost\"\n",
    "    clf10.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf10,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf10.predict(x_cv[:, None]))\n",
    "    print_results(clf10, y_testing, clf10.predict(testing[:, None]), clf10.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    \n",
    "print actual_training.shape\n",
    "print y_actual_training.shape\n",
    "print validation.shape\n",
    "print y_validation.shape\n",
    "train_classifier(actual_training, y_actual_training, validation, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
