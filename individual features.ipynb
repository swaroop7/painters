{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c06c599c2484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\x_train_pilot.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\y_train_pilot.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#x_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\x_train_wyeth.txt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#y_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\y_train_wyeth.txt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "make_submission() generates predictions for the Kaggle Painter by Numbers competion\n",
    "using simple features (image size, aspect ratio and bits/pixel^2)\n",
    "author: Swaroop Krothapalli - extended code of small yello duck\n",
    "https://github.com/swaroop7/painters\n",
    "'''\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(precision=3, linewidth=100)\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\x_train_pilot.txt')\n",
    "y_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\y_train_pilot.txt')\n",
    "\n",
    "#x_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\x_train_wyeth.txt')\n",
    "#y_train = np.loadtxt('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\y_train_wyeth.txt')\n",
    "\n",
    "\n",
    "x_train = x_train[:,7]  # Index has to be varied for each feature. \n",
    "y_train = y_train\n",
    "\n",
    "print x_train.shape, y_train.shape\n",
    "training, testing, y_training, y_testing = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "actual_training, validation, y_actual_training, y_validation = train_test_split(training, y_training, test_size=0.2, stratify=y_training, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(clf, y_test, y_pred, y_pred_prob):\n",
    "    #y_pred_prob = clf.predict_proba(y_test)[:,1]\n",
    "    #y_pred = clf.predict(y_test)\n",
    "    print 'ROC - ',roc_auc_score(y_test, y_pred_prob)\n",
    "    #print 'Confusion Matrix - ', confusion_matrix(y_test, y_pred)\n",
    "    #print 'Precision - ',precision_score(y_test, y_pred ),'Recall - ',recall_score(y_test, y_pred),'F1- Score',f1_score(y_test, y_pred),'\\n'\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print classification_report(y_test, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(x_train, y_train, x_cv, y_cv):    \n",
    "    clf1 = SVC(kernel = 'sigmoid', probability=True, class_weight='balanced')\n",
    "    clf2 = SVC(kernel = 'rbf', probability=True, class_weight='balanced')\n",
    "    clf3 = RandomForestClassifier(n_estimators=5, class_weight='balanced')\n",
    "    clf4 = GaussianNB()\n",
    "    clf5 = BernoulliNB() \n",
    "    clf6 = LinearSVC(class_weight = 'balanced', dual = False)\n",
    "    clf7 = SVC(kernel = 'poly', probability=True, class_weight='balanced', degree=2, C=1.0, tol = 0.1)\n",
    "    clf8 = neighbors.KNeighborsClassifier()\n",
    "    clf9 = linear_model.LogisticRegression( class_weight='balanced')\n",
    "    clf10 = xgb.XGBClassifier(max_depth=2, n_estimators=10, learning_rate=0.05) #objective='multi:softprob'\n",
    "    print 'starting fit'\n",
    "    #print x_train\n",
    "\n",
    "    print \"SVM - Sigmoid Scores\"\n",
    "    clf1.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf1, x_train[:, None], y_train, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf1.predict(x_cv[:, None]))\n",
    "    print_results(clf1, y_testing, clf1.predict(testing[:, None]), clf1.predict_proba(testing[:, None])[:,1] )    \n",
    "\n",
    "    print \"SVM - RBF Kernel\"\n",
    "    clf2.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf1, x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf2.predict(x_cv[:, None]))\n",
    "    print_results(clf2, y_testing, clf2.predict(testing[:, None]), clf2.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Random Forest\"\n",
    "    clf3.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf3,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf3.predict(x_cv[:, None]))\n",
    "    print_results(clf3, y_testing, clf3.predict(testing[:, None]), clf3.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Gaussian NB\"\n",
    "    clf4.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf4, x_train[:, None], y_train, cv=3)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf4.predict(x_cv[:, None]))\n",
    "    print_results(clf4, y_testing, clf4.predict(testing[:, None]), clf4.predict_proba(testing[:, None])[:,1] )        \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Bernoulli NB\"\n",
    "    clf5.fit(x_train.reshape((19,1)), y_train) \n",
    "    scores = cross_validation.cross_val_score(clf5,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf5.predict(x_cv[:, None]))\n",
    "    print_results(clf5, y_testing, clf5.predict(testing[:, None]), clf5.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"SVM - Linear Kernel\"\n",
    "    clf6.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf6, x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf6.predict(x_cv[:, None]))\n",
    "    #print_results(clf6, y_testing, clf6.predict(testing[:, None]), clf6.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    #clf7.fit(x_train.reshape((19,1)), y_train) \n",
    "    print \"KNN\"\n",
    "    clf8.fit(x_train.reshape((19,1)), y_train) \n",
    "    scores = cross_validation.cross_val_score(clf8,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf8.predict(x_cv[:, None]))\n",
    "    print_results(clf8, y_testing, clf8.predict(testing[:, None]), clf8.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"Logistic\"\n",
    "    clf9.fit(x_train.reshape((19,1)), y_train) \n",
    "    scores = cross_validation.cross_val_score(clf9,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf9.predict(x_cv[:, None]))\n",
    "    print_results(clf9, y_testing, clf9.predict(testing[:, None]), clf9.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print \"XGBoost\"\n",
    "    clf10.fit(x_train.reshape((19,1)), y_train)\n",
    "    scores = cross_validation.cross_val_score(clf10,  x_train[:, None], y_train, cv=5)\n",
    "    print \"validation_score\",accuracy_score(y_validation, clf10.predict(x_cv[:, None]))\n",
    "    print_results(clf10, y_testing, clf10.predict(testing[:, None]), clf10.predict_proba(testing[:, None])[:,1] )    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    \n",
    "print actual_training.shape\n",
    "print y_actual_training.shape\n",
    "print validation.shape\n",
    "print y_validation.shape\n",
    "train_classifier(actual_training, y_actual_training, validation, y_validation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
