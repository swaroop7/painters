{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "make_submission() generates predictions for the Kaggle Painter by Numbers competion\n",
    "using simple features (image size, aspect ratio and bits/pixel^2)\n",
    "author: Swaroop Krothapalli - extended code of small yello duck\n",
    "https://github.com/swaroop7/painters\n",
    "'''\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(precision=3, linewidth=100)\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing')\n",
    "\n",
    "\n",
    "def getEntropy(signal):\n",
    "    lensig=signal.size\n",
    "    symset=list(set(signal))\n",
    "    numsym=len(symset)\n",
    "    probabability_distribution=[np.size(signal[signal==i])/(1.0*lensig) for i in symset]\n",
    "    entropy=np.sum([p*np.log2(1.0/p) for p in probabability_distribution])\n",
    "    return entropy\n",
    "\n",
    "def calculateEntropyNeighbourhood(artwork, neighbourhood):\n",
    "    image = cv2.imread(artwork)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    colorIm=np.array(image)\n",
    "    grayIm=np.array(gray_image)\n",
    "    \n",
    "    N=neighbourhood\n",
    "    S=grayIm.shape\n",
    "    E=np.array(grayIm)\n",
    "    \n",
    "    for row in range(S[0]): \n",
    "            for col in range (S[1]): \n",
    "                    Lx=np.max([0,col-N]) \n",
    "                    Ux=np.min([S[1],col+N])\n",
    "                    Ly=np.max([0,row-N])\n",
    "                    Uy=np.min([S[0],row+N])\n",
    "                    # makes region 1-D\n",
    "                    region=grayIm[Ly:Uy,Lx:Ux].flatten()\n",
    "                    E[row,col]=getEntropy(region)\n",
    "    \n",
    "    average=np.mean(E)\n",
    "    return average\n",
    "\n",
    "def getDTM(artwork, neighbourhood):\n",
    "    image = cv2.imread(artwork)\n",
    "    image32f = np.float32(image)\n",
    "    mu    = cv2.blur(image32f,(neighbourhood,neighbourhood))\n",
    "    mu2   = cv2.blur(cv2.multiply(image32f,image32f), (neighbourhood,neighbourhood))\n",
    "    sigma = cv2.sqrt( mu2 - cv2.multiply(mu, mu) )\n",
    "    return np.mean(sigma)\n",
    "\n",
    "#image_info_test = get_image_info(test_info, 'test')\n",
    "def get_image_info(test_info, dir):\n",
    "\tif dir == 'test':\n",
    "\t\timages = list(set(list(test_info.image1.unique()) + list(test_info.image2.unique())))\n",
    "\t\tinfo = pd.DataFrame(np.array(images).reshape((-1, 1)), columns = ['filename'])\n",
    "\t\t#print info\n",
    "\telse:\n",
    "\t\tinfo = test_info\n",
    "\t\n",
    "\tinfo['pixelsx'] = np.nan\n",
    "\tinfo['pixelsy'] = np.nan\n",
    "\tinfo['size_bytes'] = np.nan\n",
    "\t#info['entropy'] = np.nan\n",
    "\tinfo['entropy1'] = np.nan\n",
    "\tinfo['entropy5'] = np.nan\n",
    "\tinfo['entropy10'] = np.nan\n",
    "\tinfo['entropy15'] = np.nan\n",
    "\tinfo['dtm1'] = np.nan\n",
    "\tinfo['dtm5'] = np.nan\n",
    "\tinfo['dtm10'] = np.nan\n",
    "\tinfo['dtm15'] = np.nan\n",
    "# \tinfo['entropy20'] = np.nan\n",
    "#\tinfo['dtm'] = np.nan\n",
    "\n",
    "\t\n",
    "\tj = 0\n",
    "\tfor i in info.index.values:\n",
    "\t\tj += 1        \n",
    "\t\ttry:\n",
    "\t\t\t#print i\n",
    "\t\t\t#fil = 'C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Wyeths\\\\'+dir+'\\\\'+info.loc[i, 'filename']\n",
    "\t\t\tfil = 'C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\'+info.loc[i, 'filename']\n",
    "\t\t\t#print fil\n",
    "\t\t\tim = Image.open('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\Pilot\\\\Artwork_for_Testing\\\\'+info.loc[i, 'filename'])\n",
    "\t\t\t#print im\n",
    "\t\t\t#print im.size\n",
    "\t\t\tinfo.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.size\n",
    "\t\t\t#im = cv2.imread(dir+'/'+info.loc[i, 'new_filename'])\n",
    "\t\t\t#info.loc[i, 'pixelsx'], info.loc[i, 'pixelsy'] = im.shape[0:2]\n",
    "\t\t\tinfo.loc[i, 'size_bytes'] = os.path.getsize(info.loc[i, 'filename'])\n",
    "\t\t\t#info.loc[i, 'entropy'] = calculateEntropyNeighbourhood(fil, 1)\n",
    "\t\t\t#print calculateEntropyNeighbourhood(fil, 1)\n",
    "#\t\t\tinfo.loc[i, 'dtm'] = getDTM(fil)\n",
    "\t\t\tinfo.loc[i, 'entropy1'] = calculateEntropyNeighbourhood(fil, 1)\n",
    "\t\t\tinfo.loc[i, 'entropy5'] = calculateEntropyNeighbourhood(fil, 5)\n",
    "\t\t\tinfo.loc[i, 'entropy10'] = calculateEntropyNeighbourhood(fil, 10)\n",
    "\t\t\tinfo.loc[i, 'entropy15'] = calculateEntropyNeighbourhood(fil, 15)\n",
    "\t\t\tinfo.loc[i, 'dtm1'] = getDTM(fil, 1)\n",
    "\t\t\tinfo.loc[i, 'dtm5'] = getDTM(fil, 5)\n",
    "\t\t\tinfo.loc[i, 'dtm10'] = getDTM(fil, 10)\n",
    "\t\t\tinfo.loc[i, 'dtm15'] = getDTM(fil, 15)\n",
    "# \t\t\tinfo.loc[i, 'entropy20'] = calculateEntropyNeighbourhood(fil, 20)\n",
    "\t\texcept:\n",
    "\t\t\tprint dir+'\\\\'+info.loc[i, 'filename']\n",
    "\t\tif (j%10 == 0):\n",
    "\t\t\tprint '',\n",
    "\tinfo=info.dropna()\n",
    "\tprint 'info shape',info.shape\n",
    "\treturn info.rename(columns={'filename' : 'new_filename'})\n",
    "\n",
    "#t = make_pairs(train_info)\t\n",
    "def make_pairs(train_info):\n",
    "\tartists = train_info.artist.unique()\n",
    "\n",
    "\tn = train_info.groupby('artist').size()\n",
    "\tn = (2*n**2).sum() \n",
    "\tt = pd.DataFrame(np.zeros((n, 4)), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "\ti = 0\n",
    "\tj = 0\n",
    "\tfor m in artists:\n",
    "\t\t\n",
    "\t\ta = train_info[train_info.artist==m][['artist', 'new_filename']].values\n",
    "\t\tuse = train_info[train_info.artist != m].index.values\n",
    "\t\tnp.random.shuffle(use)\n",
    "\t\t#print a.shape, use.shape\n",
    "\t\tnm = np.mean([a.shape[0]**2, train_info[train_info.artist != m].shape[0] ])\n",
    "\n",
    "\t\tuse = use[0:nm]\n",
    "\t\tb = train_info[train_info.artist!=m][['artist', 'new_filename']].ix[use, :].values\n",
    "\t\t#print nm, use.shape, b.shape\n",
    "\t\ta2 = pd.DataFrame(np.concatenate([np.repeat(a[:, 0], a.shape[0]).reshape((-1,1)), np.repeat(a[:, 1], a.shape[0]).reshape((-1,1)), np.tile(a, (a.shape[0], 1))], axis=1), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "\t\ta2 = a2.loc[0:nm, :]\n",
    "\t\tb2 = pd.DataFrame(np.concatenate([np.tile(a, (a.shape[0], 1))[0:b.shape[0], :], b], axis=1), columns=['artist1', 'image1', 'artist2', 'image2'])\n",
    "\t\t#print j, i, a2.shape[0], b2.shape[0]\n",
    "\t\t#print b2\n",
    "\t\tt.iloc[i:i+a2.shape[0], :] = a2.values\n",
    "\t\tt.iloc[i+a2.shape[0]:i+a2.shape[0]+b2.shape[0], :] = b2.values\n",
    "\t\ti += a2.shape[0] +b2.shape[0]\n",
    "\t\tj += 1\n",
    "\t\n",
    "\tt = t[~t.image2.isin([np.nan, 0])]\t\n",
    "\t#return t[t.image1 > t.image2]\t\n",
    "\treturn t.drop_duplicates(subset=['artist1', 'artist2','image1', 'image2'], keep=False)\n",
    "\n",
    "\t\n",
    "#x_train, y_train, x_cv, y_cv = prep_data([train_info, None], 'cv')\t\n",
    "#x_test, y_test = prep_data([None, submission_info], 'test')\t\n",
    "def prep_data(input, split):\n",
    "\tinfo = input[0]\n",
    "\tdata = input[1]\n",
    "\t\n",
    "\tif split=='cv':\n",
    "\t\t#artists = info.artist.unique()\n",
    "\t\tartists = info.artist\n",
    "\t\t#print artists\n",
    "\t\t#print 'hi', artists\n",
    "\t\tnp.random.shuffle(artists)\n",
    "\t\t\n",
    "\t\tinfo = get_image_info(info, 'train')\n",
    "\t\tinfo['bytes_per_pixel'] = 1.0*info['size_bytes']/(info['pixelsx']*info['pixelsy'])\n",
    "\t\tinfo['aspect_ratio'] = 1.0*info['pixelsx']/info['pixelsy']\t\n",
    "\t\t#train_artists = artists[0:int(0.8*len(artists))]\n",
    "\t\t#test_artists = artists[int(0.8*len(artists)):]\n",
    "\t\t#print artists\n",
    "\t\tprint 'hi',info[info.artist.isin(artists)].shape\n",
    "\t\t#train = make_pairs(info[info.artist.isin(artists)])\n",
    "\t\t#test = make_pairs(info[info.artist.isin(test_artists)])\n",
    "\t\t#print train.shape\n",
    "\t\t#train['in_train'] = True\n",
    "\t\t#test['in_train'] = True\n",
    "\t\tprint info.columns\n",
    "\t\tinfo['artist'] = info['artist'].map({'hudsonriver': 1, 'impressionist': 0})\n",
    "\t\ty_train = info['artist']\n",
    "\t\tx_train = info.drop(['artist', 'new_filename'], axis=1) \n",
    "\t\tprint x_train.columns\n",
    "\t\tprint y_train\n",
    "\t\tprint x_train\n",
    "\t\t#data['sameArtist'] = data['artist1'] == data['artist2']\n",
    "\t\t\n",
    "\tif split=='test':\n",
    "\n",
    "\t\tinfo = get_image_info(data, 'test')\n",
    "\t\tinfo['bytes_per_pixel'] = 1.0*info['size_bytes']/(info['pixelsx']*info['pixelsy'])\n",
    "\t\tinfo['aspect_ratio'] = 1.0*info['pixelsx']/info['pixelsy']\t\n",
    "\t\t\n",
    "\t\tdata['in_train'] = False\n",
    "\t\n",
    "\t\tif 'artist1' in data.columns:\n",
    "\t\t\tdata['sameArtist'] = data['artist1'] == data['artist2']\n",
    "\n",
    "\t\n",
    "\t#data2 = pd.merge(data, info[['new_filename', 'pixelsx', 'pixelsy', 'size_bytes', 'bytes_per_pixel', 'aspect_ratio']], how='left', left_on='image1', right_on='new_filename')\n",
    "\t#data2.drop('new_filename', 1, inplace=True)\n",
    "\t\n",
    "\t#data2 = pd.merge(data2, info[['new_filename', 'pixelsx', 'pixelsy', 'size_bytes', 'bytes_per_pixel', 'aspect_ratio']], how='left', left_on='image2', right_on='new_filename')\n",
    "\t#data2.drop('new_filename', 1, inplace=True)\n",
    "\t\n",
    "\t#x_train = data2[data2.in_train==True][['pixelsx_x', 'pixelsy_x', 'size_bytes_x', 'bytes_per_pixel_x', 'aspect_ratio_x', 'pixelsx_y', 'pixelsy_y', 'size_bytes_y', 'bytes_per_pixel_y', 'aspect_ratio_y']].values\n",
    "\t#x_test = data2[data2.in_train==False][['pixelsx_x', 'pixelsy_x', 'size_bytes_x', 'bytes_per_pixel_x', 'aspect_ratio_x', 'pixelsx_y', 'pixelsy_y', 'size_bytes_y', 'bytes_per_pixel_y', 'aspect_ratio_y']].values\n",
    "\t\n",
    "\t\n",
    "# \tif 'artist1' in data.columns: \n",
    "# \t\ty_train = data2[data2.in_train==True]['sameArtist'].values\n",
    "# \t\ty_test = data2[data2.in_train==False]['sameArtist'].values\n",
    "# \telse:\n",
    "# \t\ty_test = None\t\n",
    "\t\n",
    "\tif split=='cv':\t\t\n",
    "\t\treturn x_train, y_train, x_train, y_train  \n",
    " \tif split=='test':\n",
    "\t\treturn x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping training and cv data\n",
      "  train\\Segmented Images\n",
      " info shape (31, 13)\n",
      "hi (31, 15)\n",
      "Index([u'new_filename', u'artist', u'pixelsx', u'pixelsy', u'size_bytes',\n",
      "       u'entropy1', u'entropy5', u'entropy10', u'entropy15', u'dtm1', u'dtm5',\n",
      "       u'dtm10', u'dtm15', u'bytes_per_pixel', u'aspect_ratio'],\n",
      "      dtype='object')\n",
      "Index([u'pixelsx', u'pixelsy', u'size_bytes', u'entropy1', u'entropy5',\n",
      "       u'entropy10', u'entropy15', u'dtm1', u'dtm5', u'dtm10', u'dtm15',\n",
      "       u'bytes_per_pixel', u'aspect_ratio'],\n",
      "      dtype='object')\n",
      "0     1\n",
      "1     1\n",
      "2     0\n",
      "3     1\n",
      "4     1\n",
      "5     0\n",
      "6     0\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "12    0\n",
      "13    1\n",
      "14    0\n",
      "15    1\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    1\n",
      "20    1\n",
      "21    1\n",
      "22    0\n",
      "23    0\n",
      "24    1\n",
      "25    0\n",
      "27    1\n",
      "28    0\n",
      "29    1\n",
      "30    1\n",
      "31    0\n",
      "Name: artist, dtype: int64\n",
      "    pixelsx  pixelsy  size_bytes  entropy1  entropy5  entropy10  entropy15  \\\n",
      "0     957.0    571.0     84864.0  1.404312  3.731696   4.324216   4.608976   \n",
      "1     959.0    589.0     89889.0  1.568653  4.065986   4.652549   4.910624   \n",
      "2    1024.0    759.0    154870.0  1.609432  4.111257   4.676760   4.901628   \n",
      "3    1024.0    660.0    149656.0  1.546625  4.031416   4.668651   4.951489   \n",
      "4    1293.0    750.0    181995.0  1.612047  4.260729   4.871265   5.121185   \n",
      "5    1280.0    896.0    377592.0  1.827125  4.804602   5.456412   5.678610   \n",
      "6    1160.0    773.0    816809.0  1.569446  3.827517   4.337370   4.588019   \n",
      "7    1024.0    679.0     85889.0  1.091928  2.969389   3.431645   3.653589   \n",
      "8    1024.0    473.0     82052.0  1.385253  3.696588   4.290198   4.570525   \n",
      "9     750.0    412.0     59519.0  1.612922  4.373874   5.095744   5.399919   \n",
      "10    750.0    558.0     60227.0  1.407835  3.673503   4.266590   4.556287   \n",
      "11    750.0    550.0     81266.0  1.526732  4.068427   4.733292   5.013789   \n",
      "12   1840.0   1259.0   2324226.0  1.546440  3.813796   4.305754   4.514542   \n",
      "13    768.0    514.0    104284.0  1.655938  4.145484   4.676108   4.927215   \n",
      "14   1146.0    758.0    155164.0  1.523541  3.909861   4.432014   4.677864   \n",
      "15   1021.0    768.0    236336.0  1.770555  4.624366   5.184007   5.397640   \n",
      "16   2536.0   1826.0    356167.0  1.276472  3.502007   4.001087   4.225984   \n",
      "17   1045.0    600.0    201830.0  1.831027  4.846156   5.576880   5.840164   \n",
      "18   1197.0    711.0    199854.0  1.743958  4.510500   5.213714   5.372521   \n",
      "19   1207.0    961.0   1261722.0  1.555017  4.232218   4.797539   4.962465   \n",
      "20   1000.0    650.0    276391.0  1.730337  4.498618   5.122905   5.325360   \n",
      "21   1002.0    814.0    249204.0  1.868896  5.042206   5.799955   6.135000   \n",
      "22   1500.0   1163.0    314169.0  1.511064  4.135406   4.830206   5.151657   \n",
      "23   1212.0   1024.0    607323.0  1.879313  5.093622   5.920165   6.222984   \n",
      "24   1200.0    997.0    372956.0  1.837182  4.808222   5.465751   5.604545   \n",
      "25   1200.0    958.0    303919.0  1.737302  4.548508   5.207987   5.450349   \n",
      "27   1250.0   1024.0    325858.0  1.791946  4.594748   5.307801   5.559107   \n",
      "28   1280.0    972.0    267868.0  1.621373  4.182827   4.803037   5.056448   \n",
      "29   1024.0    767.0    284702.0  1.756611  4.585193   5.262217   5.535639   \n",
      "30   1411.0   1200.0    220229.0  1.407821  3.796442   4.325894   4.550178   \n",
      "31   1253.0   1024.0    341651.0  1.760748  4.778334   5.503651   5.809873   \n",
      "\n",
      "    dtm1       dtm5      dtm10      dtm15  bytes_per_pixel  aspect_ratio  \n",
      "0    0.0   6.303366   8.370016   9.729122         0.155301      1.676007  \n",
      "1    0.0   8.857413  11.285522  12.904831         0.159138      1.628183  \n",
      "2    0.0   8.868523  11.227505  12.782279         0.199262      1.349144  \n",
      "3    0.0  10.813769  13.262056  14.863419         0.221437      1.551515  \n",
      "4    0.0  10.452402  13.458271  15.190091         0.187672      1.724000  \n",
      "5    0.0  18.670391  20.745800  22.159946         0.329234      1.428571  \n",
      "6    0.0   7.840718  10.238564  11.885005         0.910926      1.500647  \n",
      "7    0.0   4.871195   6.183076   7.062562         0.123529      1.508100  \n",
      "8    0.0   7.083605   9.102629  10.513635         0.169406      2.164905  \n",
      "9    0.0  10.295783  13.660633  15.853298         0.192618      1.820388  \n",
      "10   0.0   6.943084   9.391116  11.114517         0.143912      1.344086  \n",
      "11   0.0  11.744345  15.157229  17.316908         0.197008      1.363636  \n",
      "12   0.0   8.727182  10.487931  11.579059         1.003309      1.461477  \n",
      "13   0.0   9.100098  11.269949  12.631297         0.264176      1.494163  \n",
      "14   0.0  10.168145  12.372401  13.715755         0.178623      1.511873  \n",
      "15   0.0  12.348340  14.981348  16.497532         0.301400      1.329427  \n",
      "16   0.0   4.092648   6.040420   7.309372         0.076914      1.388828  \n",
      "17   0.0  17.220572  20.304958  22.057028         0.321898      1.741667  \n",
      "18   0.0  15.873695  18.144875  19.493910         0.234828      1.683544  \n",
      "19   0.0   9.842488  12.983987  14.590188         1.087760      1.255983  \n",
      "20   0.0  14.003308  17.362064  19.113485         0.425217      1.538462  \n",
      "21   0.0  24.372662  27.505745  29.072512         0.305536      1.230958  \n",
      "22   0.0   8.218183  12.386310  15.163731         0.180091      1.289768  \n",
      "23   0.0  23.960321  27.776726  30.047966         0.489347      1.183594  \n",
      "24   0.0  16.187529  18.571636  19.832537         0.311732      1.203611  \n",
      "25   0.0  11.953973  15.026191  16.866514         0.264369      1.252610  \n",
      "27   0.0  14.070780  17.659365  19.648872         0.254577      1.220703  \n",
      "28   0.0  10.229526  13.450296  15.510250         0.215300      1.316872  \n",
      "29   0.0  15.345804  19.220169  21.381212         0.362489      1.335072  \n",
      "30   0.0   6.278040   8.968837  10.482793         0.130067      1.175833  \n",
      "31   0.0  17.295494  22.402267  24.691866         0.266276      1.223633  \n",
      "(31, 13)\n",
      "529.649049997 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "train_info = pd.read_csv('C:\\\\Users\\\\swaroop\\\\Downloads\\\\painters\\\\ImageSets\\\\pilot_medium.csv')\n",
    "#submission_info = pd.read_csv('submission_info.csv')\n",
    "print 'prepping training and cv data'\n",
    "x_train, y_train, x_cv, y_cv = prep_data([train_info, None], 'cv')\n",
    "\n",
    "print x_train.shape\n",
    "#np.savetxt('x_train_pilot.txt', x_train, fmt = '%1.3f' )\n",
    "#np.savetxt('y_train_pilot.txt', y_train, fmt = '%1.3f' )\n",
    "#x_train.to_csv(\"pd_x_train_pilot.txt\")\n",
    "#y_train.to_csv(\"pd_y_train_pilot.txt\")\n",
    "\n",
    "print (time.time() - start_time)/60 , \"minutes\"\n",
    "\n",
    "#print 'prepping test data'\n",
    "#x_test, y_test = prep_data([None, submission_info], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_train = np.loadtxt('C:/Users/swaroop/Downloads/painters/ImageSets/Pilot/Artwork_for_Testing/x_train_pilot.txt')\n",
    "# y_train = np.loadtxt('C:/Users/swaroop/Downloads/painters/ImageSets/Pilot/Artwork_for_Testing/y_train_pilot.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train['ent5_1'] = x_train['entropy5'] - x_train['entropy1']\n",
    "x_train['ent10_1'] = x_train['entropy10'] - x_train['entropy1']\n",
    "x_train['ent15_1'] = x_train['entropy15'] - x_train['entropy1']\n",
    "x_train['ent10_5'] = x_train['entropy10'] - x_train['entropy5']\n",
    "x_train['ent15_5'] = x_train['entropy15'] - x_train['entropy5']\n",
    "x_train['ent15_10'] = x_train['entropy15'] - x_train['entropy10']\n",
    "\n",
    "\n",
    "x_train['ent5d1'] = x_train['entropy5'] / x_train['entropy1']\n",
    "x_train['ent10d1'] = x_train['entropy10'] / x_train['entropy1']\n",
    "x_train['ent15d1'] = x_train['entropy15'] / x_train['entropy1']\n",
    "x_train['ent10d5'] = x_train['entropy10'] / x_train['entropy5']\n",
    "x_train['ent15d5'] = x_train['entropy15'] / x_train['entropy5']\n",
    "x_train['ent15d10'] = x_train['entropy15'] / x_train['entropy10']\n",
    "\n",
    "x_train['ent1d5'] = x_train['entropy1'] / x_train['entropy5']\n",
    "x_train['ent1d10'] = x_train['entropy1'] / x_train['entropy10']\n",
    "x_train['ent1d15'] = x_train['entropy1'] / x_train['entropy15']\n",
    "x_train['ent5d10'] = x_train['entropy5'] / x_train['entropy10']\n",
    "x_train['ent5d15'] = x_train['entropy5'] / x_train['entropy15']\n",
    "x_train['ent10d15'] = x_train['entropy10'] / x_train['entropy15']\n",
    "\n",
    "\n",
    "x_train['dtm10_5'] = x_train['dtm10'] - x_train['dtm5']\n",
    "x_train['dtm15_5'] = x_train['dtm15'] - x_train['dtm5']\n",
    "x_train['dtm15_10'] = x_train['dtm15'] - x_train['dtm10']\n",
    "\n",
    "x_train['dtm10d5'] = x_train['dtm10'] / x_train['dtm5']\n",
    "x_train['dtm15d5'] = x_train['dtm15'] / x_train['dtm5']\n",
    "x_train['dtm15d10'] = x_train['dtm15'] / x_train['dtm10']\n",
    "\n",
    "x_train['dtm5d10'] = x_train['dtm5'] / x_train['dtm10']\n",
    "x_train['dtm5d15'] = x_train['dtm5'] / x_train['dtm15']\n",
    "x_train['dtm10d15'] = x_train['dtm10'] / x_train['dtm15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_classifier(x_train, y_train, x_train, y_train) \n",
    "#print (time.time() - start_time)/60 , \"minutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def print_results(clf, y_test, y_pred, y_pred_prob):\n",
    "    #y_pred_prob = clf.predict_proba(y_test)[:,1]\n",
    "    #y_pred = clf.predict(y_test)\n",
    "    print 'ROC - ',roc_auc_score(y_test, y_pred_prob)\n",
    "    print 'Confusion Matrix - ', confusion_matrix(y_test, y_pred)\n",
    "    #print 'Precision - ',precision_score(y_test, y_pred ),'Recall - ',recall_score(y_test, y_pred),'F1- Score',f1_score(y_test, y_pred),'\\n'\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print classification_report(y_test, y_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 31) (31L,)\n",
      "(24, 31) (7, 31)\n",
      "[[ 0 12]\n",
      " [ 1 12]]\n",
      "[[0 4]\n",
      " [1 3]]\n",
      "[[0 2]\n",
      " [1 2]]\n",
      "[[ 0 16]\n",
      " [ 1 15]]\n",
      "[[ 0 10]\n",
      " [ 1 10]]\n",
      "13    1\n",
      "6     0\n",
      "22    0\n",
      "20    1\n",
      "Name: artist, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape, y_train.shape\n",
    "training, testing, y_training, y_testing = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "actual_training, validation, y_actual_training, y_validation = train_test_split(training, y_training, test_size=0.2, stratify=y_training, random_state=42)\n",
    "print training.shape, testing.shape\n",
    "#print y_training, y_testing\n",
    "print itemfreq(y_training)\n",
    "print itemfreq(y_testing)\n",
    "print itemfreq(y_validation)\n",
    "print itemfreq(y_train)\n",
    "print itemfreq(y_actual_training)\n",
    "\n",
    "print y_validation\n",
    "# print y_actual_training\n",
    "# print actual_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 0.583333333333 0.190029237517 0.4 0.714285714286\n",
      "ROC -  0.833333333333\n",
      "Confusion Matrix -  [[2 2]\n",
      " [0 3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.50      0.67         4\n",
      "    class 1       0.60      1.00      0.75         3\n",
      "\n",
      "avg / total       0.83      0.71      0.70         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "for i in xrange(1):\n",
    "    clf = RandomForestClassifier(n_estimators=9, class_weight='balanced', n_jobs = -1, random_state = 42)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, scores.mean(), scores.std(), accuracy_score(y_validation, y_pred_valid), accuracy_score(y_testing, clf.predict(testing))\n",
    "    \n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 \t0.3 \t0.1 \t0.25 \t0.571428571429\n",
      "ROC -  0.5\n",
      "Confusion Matrix -  [[2 2]\n",
      " [1 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.67      0.50      0.57         4\n",
      "    class 1       0.50      0.67      0.57         3\n",
      "\n",
      "avg / total       0.60      0.57      0.57         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGB\n",
    "    \n",
    "learning_r_col = [0.01, 0.02, 0.03, 0.04,0.05,0.06,0.07,0.08,0.09,0.1]    \n",
    "    \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "\n",
    "    \n",
    "for i in xrange(1):\n",
    "    clf = xgb.XGBClassifier(max_depth=2, n_estimators=22, learning_rate=0.05, nthread = -1) #objective='multi:softprob'\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_testing, clf.predict(testing))\n",
    "\n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 \t0.6 \t0.122474487139 \t0.5 \t0.571428571429\n",
      "ROC -  0.583333333333\n",
      "Confusion Matrix -  [[2 2]\n",
      " [1 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.67      0.50      0.57         4\n",
      "    class 1       0.50      0.67      0.57         3\n",
      "\n",
      "avg / total       0.60      0.57      0.57         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic\n",
    "    \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"    \n",
    "    \n",
    "for i in xrange(1):\n",
    "    clf = linear_model.LogisticRegression( class_weight='balanced', max_iter = 13)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_testing, clf.predict(testing))\n",
    "    \n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS of 5 fold CV\n",
      "Mean Accuracy  \tSTD \tValidation  \tTest\n",
      "0 \t0.6 \t0.122474487139 \t0.5 \t0.571428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.67      0.50      0.57         4\n",
      "    class 1       0.50      0.67      0.57         3\n",
      "\n",
      "avg / total       0.60      0.57      0.57         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "    \n",
    "print \"ACCURACY RESUTLS of 5 fold CV\"    \n",
    "print \"Mean Accuracy \",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"    \n",
    "\n",
    "iter = [10,100,500,1000]\n",
    "\n",
    "for i in xrange(1):\n",
    "    clf = LinearSVC(class_weight = 'balanced', dual = False, max_iter = 9)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_testing, clf.predict(testing))\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "print classification_report(y_testing, clf.predict(testing), target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "auto 0.3 0.1 0.75 0.571428571429\n",
      "ball_tree 0.3 0.1 0.75 0.571428571429\n",
      "kd_tree 0.3 0.1 0.75 0.571428571429\n",
      "brute 0.3 0.1 0.75 0.571428571429\n",
      "ROC -  0.625\n",
      "Confusion Matrix -  [[1 3]\n",
      " [0 3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.25      0.40         4\n",
      "    class 1       0.50      1.00      0.67         3\n",
      "\n",
      "avg / total       0.79      0.57      0.51         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "alg =  [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "for i in alg:\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=3, algorithm = i, weights = 'uniform')\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, scores.mean(), scores.std(), accuracy_score(y_validation, y_pred_valid), accuracy_score(y_testing, clf.predict(testing))\n",
    "    \n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "0 0.466666666667 0.0666666666667 0.6 0.571428571429\n",
      "ROC -  0.5\n",
      "Confusion Matrix -  [[4 0]\n",
      " [3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.57      1.00      0.73         4\n",
      "    class 1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.33      0.57      0.42         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM RBF\n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "\n",
    "for i in xrange(1):\n",
    "    clf = SVC(C=1, kernel = 'rbf',  degree=1, probability=True, class_weight='balanced', shrinking=False, gamma = 'auto')\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, scores.mean(), scores.std(), accuracy_score(y_validation, y_pred_valid), accuracy_score(y_testing, clf.predict(testing))\n",
    "    \n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(x_train, y_train, x_cv, y_cv):    \n",
    "    clf1 = SVC(kernel = 'sigmoid', probability=True, class_weight='balanced')\n",
    "    clf2 = SVC(kernel = 'rbf', probability=True, class_weight='balanced')\n",
    "    clf3 = RandomForestClassifier(n_estimators=5, class_weight='balanced', n_jobs = -1)\n",
    "    clf4 = GaussianNB()\n",
    "    clf5 = BernoulliNB() \n",
    "    clf6 = LinearSVC(class_weight = 'balanced', dual = False)\n",
    "    clf7 = SVC(kernel = 'poly', probability=True, class_weight='balanced', degree=2, C=1.0, tol = 0.1)\n",
    "    clf8 = neighbors.KNeighborsClassifier()\n",
    "    clf9 = linear_model.LogisticRegression( class_weight='balanced')\n",
    "    clf10 = xgb.XGBClassifier(max_depth=2, n_estimators=10, learning_rate=0.05) #objective='multi:softprob'\n",
    "    print 'starting fit'\n",
    "    \n",
    "    print x_train.shape, y_train.shape\n",
    "    training, testing, y_training, y_testing = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "    \n",
    "    print training.shape, testing.shape\n",
    "    #print y_training, y_testing\n",
    "    print itemfreq(y_training)\n",
    "    print itemfreq(y_testing)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     clf1.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf1, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"SVM - Sigmoid Scores\",\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf2.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf2, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"SVM - RBF Kernel\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    clf3.fit(training, y_training)\n",
    "    scores = cross_validation.cross_val_score(clf3, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "    print \"Random Forest\", \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    clf4.fit(training, y_training)\n",
    "    scores = cross_validation.cross_val_score(clf4, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"Gaussian NB\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    clf5.fit(training, y_training) \n",
    "    scores = cross_validation.cross_val_score(clf5, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"Bernoulli NB\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    clf6.fit(training, y_training)\n",
    "    scores = cross_validation.cross_val_score(clf6, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "    print \"SVM - Linear Kernel\", \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf7.fit(training, y_training) \n",
    "    clf8.fit(training, y_training) \n",
    "    scores = cross_validation.cross_val_score(clf8, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"KNN\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    clf9.fit(training, y_training) \n",
    "    scores = cross_validation.cross_val_score(clf9, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "    print \"Logistic\", \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    clf10.fit(training, y_training)\n",
    "    scores = cross_validation.cross_val_score(clf10, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "    print \"XGBoost\", \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "\n",
    "#     print 'SVM - Sigmoid Kernel'\n",
    "#     print_results(clf1, y_testing, clf1.predict(testing), clf1.predict_proba(testing)[:,1] )\n",
    "#     print 'SVM - rbf Kernel'\n",
    "#     print_results(clf2, y_testing, clf2.predict(testing), clf2.predict_proba(testing)[:,1] )\n",
    "    print 'Random Forest'\n",
    "    print_results(clf3, y_testing, clf3.predict(testing), clf3.predict_proba(testing)[:,1] )\n",
    "#     print 'Gaussian NB'\n",
    "#     print_results(clf4, y_testing, clf4.predict(testing), clf4.predict_proba(testing)[:,1] )\n",
    "#     print 'Bernoulli NB'\n",
    "#     print_results(clf5, y_testing, clf5.predict(testing), clf5.predict_proba(testing)[:,1] )\n",
    "    print 'SVM Linear Kernel'    \n",
    "    prob_pos = clf6.decision_function(testing)\n",
    "    prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    print_results(clf6, y_testing, clf6.predict(testing), prob_pos )\n",
    "#     print 'SVM Polynomial Kernel'\n",
    "#     print_results(clf7, y_testing, clf7.predict(testing), clf7.predict_proba(testing)[:,1] )\n",
    "#     print 'Nearest Neighbours'\n",
    "#     print_results(clf8, y_testing, clf8.predict(testing), clf8.predict_proba(testing)[:,1] )\n",
    "    print 'Logistic Regression'\n",
    "    print_results(clf9, y_testing, clf9.predict(testing), clf9.predict_proba(testing)[:,1] )\n",
    "    print 'XG Boost'\n",
    "    print_results(clf10, y_testing, clf10.predict(testing), clf10.predict_proba(testing)[:,1] )\n",
    "    \n",
    "def print_results(clf, y_test, y_pred, y_pred_prob):\n",
    "    #y_pred_prob = clf.predict_proba(y_test)[:,1]\n",
    "    #y_pred = clf.predict(y_test)\n",
    "    print 'ROC - ',roc_auc_score(y_test, y_pred_prob)\n",
    "    print 'Confusion Matrix - ', confusion_matrix(y_test, y_pred)\n",
    "    #print 'Precision - ',precision_score(y_test, y_pred ),'Recall - ',recall_score(y_test, y_pred),'F1- Score',f1_score(y_test, y_pred),'\\n'\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print classification_report(y_test, y_pred, target_names=target_names)\n",
    "\n",
    "\n",
    "\n",
    "def train_classifier2(x_train, y_train, x_cv, y_cv):    \n",
    "    clf1 = SVC(kernel = 'sigmoid', probability=True, class_weight='balanced')\n",
    "    clf2 = SVC(kernel = 'rbf', probability=True, class_weight='balanced')\n",
    "    clf3 = RandomForestClassifier(n_estimators=5, class_weight='balanced', n_jobs = -1)\n",
    "    clf4 = GaussianNB()\n",
    "    clf5 = BernoulliNB() \n",
    "    clf6 = LinearSVC(class_weight = 'balanced', dual = False)\n",
    "    clf7 = SVC(kernel = 'poly', probability=True, class_weight='balanced', degree=2, C=1.0, tol = 0.1)\n",
    "    clf8 = neighbors.KNeighborsClassifier()\n",
    "    clf9 = linear_model.LogisticRegression( class_weight='balanced')\n",
    "    clf10 = xgb.XGBClassifier(max_depth=2, n_estimators=10, learning_rate=0.05) #objective='multi:softprob'\n",
    "    print 'starting fit'\n",
    "    \n",
    "    print x_train.shape, y_train.shape\n",
    "    training, testing, y_training, y_testing = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "    actual_training, validation, y_actual_training, y_validation = train_test_split(training, y_training, test_size=0.2, stratify=y_train, random_state=42)\n",
    "    print training.shape, testing.shape\n",
    "    #print y_training, y_testing\n",
    "    print itemfreq(y_training)\n",
    "    print itemfreq(y_testing)\n",
    "    \n",
    "    for i in xrange(0,50):\n",
    "        clf3 = RandomForestClassifier(n_estimators=i, class_weight='balanced', n_jobs = -1)\n",
    "        clf3.fit\n",
    "    \n",
    "#     clf1.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf1, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"SVM - Sigmoid Scores\",\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf2.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf2, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"SVM - RBF Kernel\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf3.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf3, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"Random Forest\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf4.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf4, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"Gaussian NB\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf5.fit(training, y_training) \n",
    "#     scores = cross_validation.cross_val_score(clf5, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"Bernoulli NB\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf6.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf6, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"SVM - Linear Kernel\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf7.fit(training, y_training) \n",
    "#     clf8.fit(training, y_training) \n",
    "#     scores = cross_validation.cross_val_score(clf8, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"KNN\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf9.fit(training, y_training) \n",
    "#     scores = cross_validation.cross_val_score(clf9, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"Logistic\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#     clf10.fit(training, y_training)\n",
    "#     scores = cross_validation.cross_val_score(clf10, training, y_training, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "#     print \"XGBoost\", \n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "\n",
    "#     print 'SVM - Sigmoid Kernel'\n",
    "#     print_results(clf1, y_testing, clf1.predict(testing), clf1.predict_proba(testing)[:,1] )\n",
    "#     print 'SVM - rbf Kernel'\n",
    "#     print_results(clf2, y_testing, clf2.predict(testing), clf2.predict_proba(testing)[:,1] )\n",
    "    print 'Random Forest'\n",
    "    print_results(clf3, y_testing, clf3.predict(testing), clf3.predict_proba(testing)[:,1] )\n",
    "#     print 'Gaussian NB'\n",
    "#     print_results(clf4, y_testing, clf4.predict(testing), clf4.predict_proba(testing)[:,1] )\n",
    "#     print 'Bernoulli NB'\n",
    "#     print_results(clf5, y_testing, clf5.predict(testing), clf5.predict_proba(testing)[:,1] )\n",
    "#     print 'SVM Linear Kernel'    \n",
    "#     prob_pos = clf6.decision_function(testing)\n",
    "#     prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "#     print_results(clf6, y_testing, clf6.predict(testing), prob_pos )\n",
    "#     print 'SVM Polynomial Kernel'\n",
    "#     print_results(clf7, y_testing, clf7.predict(testing), clf7.predict_proba(testing)[:,1] )\n",
    "#     print 'Nearest Neighbours'\n",
    "#     print_results(clf8, y_testing, clf8.predict(testing), clf8.predict_proba(testing)[:,1] )\n",
    "#     print 'Logistic Regression'\n",
    "#     print_results(clf9, y_testing, clf9.predict(testing), clf9.predict_proba(testing)[:,1] )\n",
    "#     print 'XG Boost'\n",
    "#     print_results(clf10, y_testing, clf10.predict(testing), clf10.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY RESUTLS\n",
      "Mean Accuracy of 5 fold CV \tSTD \tValidation  \tTest\n",
      "1 0.4 0.122474487139 0.25 0.285714285714\n",
      "2 0.5 0.158113883008 0.5 0.285714285714\n",
      "3 0.45 0.187082869339 0.5 0.285714285714\n",
      "4 0.4 0.2 0.5 0.285714285714\n",
      "5 0.35 0.122474487139 0.5 0.285714285714\n",
      "6 0.4 0.25495097568 0.75 0.285714285714\n",
      "7 0.35 0.3 0.75 0.285714285714\n",
      "8 0.35 0.3 0.75 0.428571428571\n",
      "9 0.3 0.291547594742 0.75 0.428571428571\n",
      "10 0.35 0.3 0.75 0.428571428571\n",
      "11 0.3 0.244948974278 0.75 0.285714285714\n",
      "12 0.35 0.3 0.75 0.428571428571\n",
      "13 0.3 0.244948974278 0.75 0.428571428571\n",
      "14 0.3 0.244948974278 0.75 0.571428571429\n",
      "15 0.25 0.22360679775 0.75 0.428571428571\n",
      "16 0.3 0.187082869339 0.75 0.571428571429\n",
      "17 0.35 0.2 0.5 0.285714285714\n",
      "18 0.35 0.2 0.75 0.428571428571\n",
      "19 0.3 0.187082869339 0.75 0.285714285714\n",
      "20 0.3 0.187082869339 0.75 0.428571428571\n",
      "21 0.25 0.22360679775 0.75 0.428571428571\n",
      "22 0.3 0.187082869339 0.75 0.428571428571\n",
      "23 0.3 0.187082869339 0.75 0.428571428571\n",
      "24 0.3 0.187082869339 0.75 0.428571428571\n",
      "25 0.2 0.187082869339 0.75 0.571428571429\n",
      "26 0.25 0.22360679775 0.75 0.428571428571\n",
      "27 0.25 0.22360679775 0.75 0.428571428571\n",
      "28 0.25 0.22360679775 0.75 0.428571428571\n",
      "29 0.25 0.22360679775 0.75 0.428571428571\n",
      "30 0.3 0.291547594742 0.75 0.285714285714\n",
      "31 0.2 0.187082869339 0.75 0.285714285714\n",
      "32 0.2 0.187082869339 0.75 0.285714285714\n",
      "33 0.25 0.22360679775 0.75 0.285714285714\n",
      "34 0.2 0.187082869339 0.75 0.285714285714\n",
      "35 0.2 0.187082869339 0.75 0.285714285714\n",
      "36 0.3 0.187082869339 0.75 0.285714285714\n",
      "37 0.3 0.187082869339 0.75 0.285714285714\n",
      "38 0.3 0.187082869339 0.75 0.285714285714\n",
      "39 0.3 0.187082869339 0.75 0.285714285714\n",
      "40 0.3 0.187082869339 0.75 0.285714285714\n",
      "41 0.3 0.187082869339 0.75 0.285714285714\n",
      "42 0.3 0.187082869339 0.75 0.285714285714\n",
      "43 0.35 0.2 0.75 0.428571428571\n",
      "44 0.35 0.2 0.75 0.285714285714\n",
      "45 0.35 0.2 0.75 0.285714285714\n",
      "46 0.35 0.2 0.75 0.285714285714\n",
      "47 0.35 0.2 0.75 0.285714285714\n",
      "48 0.35 0.2 0.75 0.285714285714\n",
      "49 0.35 0.2 0.75 0.285714285714\n",
      "ROC -  0.25\n",
      "Confusion Matrix -  [[2 2]\n",
      " [3 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.40      0.50      0.44         4\n",
      "    class 1       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.23      0.29      0.25         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "for i in xrange(1,50):\n",
    "    clf = RandomForestClassifier(n_estimators=i, class_weight='balanced', n_jobs = -1, random_state = 42)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, scores.mean(), scores.std(), accuracy_score(y_validation, y_pred_valid), accuracy_score(y_testing, clf.predict(testing))\n",
    "    \n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGB\n",
    "    \n",
    "learning_r_col = [0.01, 0.02, 0.03, 0.04,0.05,0.06,0.07,0.08,0.09,0.1]    \n",
    "    \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"        \n",
    "\n",
    "\n",
    "    \n",
    "for i in xrange(1):\n",
    "    clf = xgb.XGBClassifier(max_depth=2, n_estimators=22, learning_rate=0.05, nthread = -1) #objective='multi:softprob'\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_testing, clf.predict(testing))\n",
    "\n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic\n",
    "    \n",
    "print \"ACCURACY RESUTLS\"    \n",
    "print \"Mean Accuracy of 5 fold CV\",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"    \n",
    "    \n",
    "for i in xrange(1):\n",
    "    clf = linear_model.LogisticRegression( class_weight='balanced', max_iter = 13)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_testing, clf.predict(testing))\n",
    "    \n",
    "print_results(clf, y_testing, clf.predict(testing), clf.predict_proba(testing)[:,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "    \n",
    "print \"ACCURACY RESUTLS of 5 fold CV\"    \n",
    "print \"Mean Accuracy \",\"\\t\", \"STD\",\"\\t\", \"Validation \",\"\\t\", \"Test\"    \n",
    "\n",
    "iter = [10,100,500,1000]\n",
    "\n",
    "for i in xrange(1):\n",
    "    clf = LinearSVC(class_weight = 'balanced', dual = False, max_iter = 9)\n",
    "    clf.fit(actual_training, y_actual_training)\n",
    "    scores = cross_validation.cross_val_score(clf, actual_training, y_actual_training, cv=5, n_jobs = -1)\n",
    "    y_pred_valid = clf.predict(validation)\n",
    "    print i, \"\\t\",scores.mean(),\"\\t\", scores.std(), \"\\t\",accuracy_score(y_validation, y_pred_valid), \"\\t\",accuracy_score(y_testing, clf.predict(testing))\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "print classification_report(y_testing, clf.predict(testing), target_names=target_names)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
